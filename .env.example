# Azure AI Inference SDK Model Switcher - Environment Configuration Template
# Copy this file to .env and update with your actual values

# Azure AI Foundry Endpoint
# Replace with your actual Azure AI Foundry endpoint URL
endpoint="https://your-ai-foundry-endpoint.inference.ai.azure.com"

# Model Names (deployed in Azure AI Foundry)
# These should match the model deployment names in your Azure AI Foundry
grok_model="grok-3-mini"
deep_seek_model="DeepSeek-R1"

# Azure AI Search Configuration
# Replace with your actual Azure AI Search service details
ai_search_url="https://your-search-service.search.windows.net"
ai_index_name="your-index-name"
ai_semantic_config="your-semantic-config-name"

# Azure AI Search API Key (optional - use only if not using DefaultAzureCredential)
# For production, it's recommended to use Azure RBAC instead of API keys. The API key is not mandatory in this sample, since it uses managed identity.
ai_search_key="your-search-api-key-here"

# Azure AI API Key (optional - use only if not using DefaultAzureCredential)
# For production, it's recommended to use Azure RBAC instead of API keys
# api_key="your-ai-service-api-key-here"

# Notes:
# - This template uses API keys for simplicity, but Azure RBAC is recommended for production
# - If using Azure RBAC, you can omit the api_key and ai_search_key variables
# - Ensure your Azure identity has the following roles:
#   * Cognitive Services User (for AI models)
#   * Search Index Data Reader (for Azure AI Search)
